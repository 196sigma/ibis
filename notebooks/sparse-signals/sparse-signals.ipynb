{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5211241",
   "metadata": {},
   "source": [
    "# Spare Signals\n",
    "Created: 07/12/2024\\\n",
    "Updated: 07/13/2024\n",
    "\n",
    "## Notes\n",
    "* Outline dataflow and transformations to create something like unit tests\n",
    "* move to AWS/Colab\n",
    "* simulate [See Chinco gist](https://gist.github.com/alexchinco/467325abbf11d5c8f565)\n",
    "* restrict to trading days and model overnight separately\n",
    "* keep track of selected stocks and their coefficients\n",
    "* precompute the 30 minute training windows\n",
    "* Use SGDRegressor with L1 instead of LassoCV\n",
    "* Use Numpy instead of Pandas\n",
    "* Remove stocks with limited obs\n",
    "* Impute missing values\n",
    "* use a strategy to compute sharpe ratios over\n",
    "* compute pct over/under metrics; max/min error; other asymmetric metrics\n",
    "* Try other LLMs to critique the code\n",
    "* Re-implement in Julia\n",
    "* Speed up with Spark, Dask, Ray, or C++. ([See ChatGPT discussion](https://chatgpt.com/share/d010299a-3bb5-4230-8389-3530de660cf9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c15e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress statsmodels warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "\n",
    "\n",
    "_start_year = 2017\n",
    "start_year = pd.to_datetime(f\"{_start_year}-01-01 00:00:00\")\n",
    "_end_year = 2017\n",
    "end_year = pd.to_datetime(f\"{_end_year}-12-31 23:59:59\")\n",
    "asset_type = 'stock'\n",
    "period = '1min'\n",
    "timeframe = 'full'\n",
    "adjustment = 'adjsplitdiv'\n",
    "N_TICKERS = 300\n",
    "\n",
    "def add_trading_hours(df):\n",
    "    \"\"\"\n",
    "    Add indicator for trading hours\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        Must have index as datetime\n",
    "    \"\"\"\n",
    "    trading_start = 930\n",
    "    trading_end = 1600\n",
    "    df['time'] = df.index.strftime('%H%M').astype(int)\n",
    "    df['is_trading_hour'] = (df['time'] >= trading_start) & (df['time'] <= trading_end)\n",
    "    return df\n",
    "\n",
    "# check operating system\n",
    "if os.name == 'nt':\n",
    "    CSV_DEST_DIR = f\"E:/frd-historical/data/{asset_type}/{period}/csv/\"\n",
    "else:\n",
    "    CSV_DEST_DIR = f\"/media/reggie/reg_ext/frd-historical/data/{asset_type}/{period}/csv/\"\n",
    "print(f\"{len(os.listdir(CSV_DEST_DIR))} files found in {CSV_DEST_DIR}\")\n",
    "os.listdir(CSV_DEST_DIR)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('return_features_df.pickle', 'rb') as file:\n",
    "    return_features_df = pickle.load(file)\n",
    "print(return_features_df.shape)\n",
    "print(return_features_df.info())\n",
    "\n",
    "tickers = list(set([col.split(\"_\")[0] for col in return_features_df.columns]))\n",
    "len(tickers)\n",
    "print(f\"Number of tickers: {len(tickers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a13a11",
   "metadata": {},
   "source": [
    "# First slow attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ecfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rolling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = return_features_df.copy()\n",
    "#data = data.iloc[:32]\n",
    "focal_ticker = 'AAPL'\n",
    "window_size = 30\n",
    "prediction_horizon = 1\n",
    "lasso_cv = 10\n",
    "#def rolling_window_predictions(data, focal_ticker, window_size=30, prediction_horizon=1):\n",
    "# Identify columns for the focal ticker\n",
    "focal_columns = [f'{focal_ticker}_return', \n",
    "                    f'{focal_ticker}_lag_1_return', \n",
    "                    f'{focal_ticker}_lag_2_return', \n",
    "                    f'{focal_ticker}_lag_3_return']\n",
    "\n",
    "# Prepare the list of all lagged columns\n",
    "#lagged_columns = [col for col in data.columns if 'lag' in col]\n",
    "lagged_columns = []\n",
    "for ticker in tickers:\n",
    "    for i in range(1, 4):\n",
    "        lagged_columns.append(f'{ticker}_lag_{i}_return')\n",
    "results = {'date': [], 'lasso': [], 'ar': [], 'ret': [], 'tickers': [], 'lasso_coef': []}\n",
    "\n",
    "n_windows = len(data) - window_size - prediction_horizon\n",
    "\n",
    "lagged_columns_df = data[lagged_columns]\n",
    "\n",
    "for i in tqdm(range(window_size, len(data) - prediction_horizon)):\n",
    "    start_idx = i - window_size\n",
    "    end_idx = i\n",
    "\n",
    "    # Prepare predictors (X) and response (y)\n",
    "    _X = data[lagged_columns].iloc[start_idx:end_idx]\n",
    "    _y = data[f'{focal_ticker}_return'].iloc[start_idx:end_idx]\n",
    "    #print(f\"start_idx: {start_idx}, end_idx: {end_idx}, X dim: {_X.shape}, y dim: {_y.shape}\")\n",
    "    if len(_X) < 5 or len(_y) < 5:  # Ensure there are enough samples for cross-validation\n",
    "        continue\n",
    "    \n",
    "    X = _X.values\n",
    "    y = _y.values\n",
    "\n",
    "    # LASSO Model\n",
    "    lasso = LassoCV(cv=lasso_cv, n_jobs=10).fit(X, y)\n",
    "    #latest_data = lagged_columns_df.iloc[end_idx:end_idx+1].dropna()\n",
    "    latest_data = lagged_columns_df.iloc[end_idx:end_idx+1]\n",
    "    if latest_data.empty:\n",
    "        continue\n",
    "    lasso_pred = lasso.predict(latest_data)[0]\n",
    "    \n",
    "    # AR Model\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ar_model = AutoReg(data[f'{focal_ticker}_return'].iloc[start_idx:end_idx].dropna(), lags=10).fit()\n",
    "        #ar_pred = ar_model.predict(start=len(ar_model.model.endog), end=len(ar_model.model.endog))[0]\n",
    "        ar_pred = float(ar_model.predict(start=len(ar_model.model.endog), end=len(ar_model.model.endog)))\n",
    "\n",
    "    # Store predictions\n",
    "    results['date'].append(data.index[end_idx + prediction_horizon])\n",
    "    results['lasso'].append(lasso_pred)\n",
    "    results['ar'].append(ar_pred)\n",
    "    results['ret'].append(y[-1])\n",
    "    results['lasso_coef'].append(lasso.coef_)\n",
    "\n",
    "    #return results\n",
    "\n",
    "#results = rolling_window_predictions(return_features_df, focal_ticker)\n",
    "\n",
    "# Convert results to DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.set_index('date', inplace=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_features_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = return_features_df.reset_index().values\n",
    "# Create column names\n",
    "column_names = ['date']\n",
    "for ticker in tickers:\n",
    "    column_names.extend([f'{ticker}_return'] + [f'{ticker}_lag_{i}_return' for i in range(1, 4)])\n",
    "\n",
    "# Assuming the first column is the date\n",
    "dates = data[:, 0]\n",
    "\n",
    "# Find indices of relevant columns\n",
    "focal_indices = [column_names.index(f'{focal_ticker}_return')]\n",
    "focal_indices.extend([column_names.index(f'{focal_ticker}_lag_{i}_return') for i in range(1, 4)])\n",
    "\n",
    "lagged_indices = []\n",
    "for ticker in tickers:\n",
    "    for i in range(1, 4):\n",
    "        lagged_indices.append(column_names.index(f'{ticker}_lag_{i}_return'))\n",
    "\n",
    "results = {'date': [], 'lasso': [], 'ar': [], 'ret': [], 'lasso_coef': []}\n",
    "\n",
    "n_windows = len(data) - window_size - prediction_horizon\n",
    "\n",
    "lagged_columns_array = data[:, lagged_indices]\n",
    "\n",
    "for i in tqdm(range(window_size, len(data) - prediction_horizon)):\n",
    "    start_idx = i - window_size\n",
    "    end_idx = i\n",
    "\n",
    "    # Prepare predictors (X) and response (y)\n",
    "    _X = data[start_idx:end_idx, lagged_indices]\n",
    "    _y = data[start_idx:end_idx, focal_indices[0]]\n",
    "\n",
    "    if len(_X) < 5 or len(_y) < 5:  # Ensure there are enough samples for cross-validation\n",
    "        continue\n",
    "    \n",
    "    X = _X\n",
    "    y = _y\n",
    "\n",
    "    # LASSO Model\n",
    "    lasso = LassoCV(cv=lasso_cv, n_jobs=10).fit(X, y)\n",
    "    latest_data = lagged_columns_array[end_idx:end_idx+1]\n",
    "    if latest_data.size == 0:\n",
    "        continue\n",
    "    lasso_pred = lasso.predict(latest_data)[0]\n",
    "    \n",
    "    # AR Model\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ar_model = AutoReg(y, lags=10).fit()\n",
    "        ar_pred = float(ar_model.predict(start=len(ar_model.model.endog), end=len(ar_model.model.endog)))\n",
    "\n",
    "    # Store predictions\n",
    "    results['date'].append(dates[end_idx + prediction_horizon])\n",
    "    results['lasso'].append(lasso_pred)\n",
    "    results['ar'].append(ar_pred)\n",
    "    results['ret'].append(y[-1])\n",
    "    results['lasso_coef'].append(lasso.coef_)\n",
    "\n",
    "# Convert results to numpy array for easier analysis\n",
    "results_array = np.array([(d, l, a, r, *lc) for d, l, a, r, lc in zip(\n",
    "    results['date'], results['lasso'], results['ar'], results['ret'], results['lasso_coef']\n",
    ")])\n",
    "\n",
    "# If you need to convert back to pandas DataFrame:\n",
    "# import pandas as pd\n",
    "# results_df = pd.DataFrame(results_array, columns=['date', 'lasso', 'ar', 'ret'] + [f'lasso_coef_{i}' for i in range(len(results['lasso_coef'][0]))])\n",
    "# results_df.set_index('date', inplace=True)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e30b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-cache windows\n",
    "X_rolling = []\n",
    "y_rolling = []\n",
    "for i in range(window_size, len(data) - prediction_horizon):\n",
    "    start_idx = i - window_size\n",
    "    end_idx = i\n",
    "    _X = data[start_idx:end_idx, lagged_indices]\n",
    "    _y = data[start_idx:end_idx, focal_indices[0]]\n",
    "    X_rolling.append(_X)\n",
    "    y_rolling.append(_y)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb97556",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_idx, prediction_horizon, data.index[end_idx + prediction_horizon]\n",
    "lasso_pred, ar_pred, y[-1], max(1000*lasso.coef_)\n",
    "len(results['date']), len(results['lasso']), len(results['ar']), len(results['ret']), len(results['lasso_coef'])\n",
    "date_df = pd.DataFrame(results['date'], columns=['date'])\n",
    "lasso_df = pd.DataFrame(results['lasso'], columns=['lasso'])\n",
    "ar_df = pd.DataFrame(results['ar'], columns=['ar'])\n",
    "ret_df = pd.DataFrame(results['ret'], columns=['ret'])\n",
    "date_df\n",
    "lasso_df\n",
    "ar_df\n",
    "ret_df\n",
    "results_df = pd.concat([date_df, lasso_df, ar_df, ret_df], axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'x': [-2, -1, 0], 'y': [1, 2, 3], 'z': [4, 5, 6]}\n",
    "# get dict with only x and y\n",
    "{k: v for k, v in d.items() if k in ['x', 'y']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({k: v for k, v in results.items() if k in ['date', 'lasso', 'ar', 'ret']})\n",
    "results_df.set_index('date', inplace=True)\n",
    "results_df\n",
    "\n",
    "\n",
    "lasso_results = {'date': [], 'max_coef': [], 'min_coef': [], 'abs_max_coef': [], 'n_coefs_gt_0': [], 'n_coefs_lt_0': []}\n",
    "for date in results['date']:\n",
    "    idx = results['date'].index(date)\n",
    "    coefs = results['lasso_coef'][idx]\n",
    "    lasso_results['date'].append(date)\n",
    "    lasso_results['max_coef'].append(max(coefs))\n",
    "    lasso_results['min_coef'].append(min(coefs))\n",
    "    lasso_results['abs_max_coef'].append(max(abs(coefs)))\n",
    "    lasso_results['n_coefs_gt_0'].append(sum(coef > 0 for coef in coefs))\n",
    "    lasso_results['n_coefs_lt_0'].append(sum(coef < 0 for coef in coefs))\n",
    "lasso_results_df = pd.DataFrame(lasso_results)\n",
    "lasso_results_df.set_index('date', inplace=True)\n",
    "\n",
    "lasso_results_df.to_csv(\"lasso-results-df.csv\")\n",
    "with open('lasso_results_df.pickle', 'wb') as file:\n",
    "    pickle.dump(lasso_results_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['abs_min_coef'] = X['min_coef'].abs()\n",
    "# set biggest coef to max(X['max_coef'], X['abs_min_coef])\n",
    "X['max_coef'] = X[['max_coef', 'abs_min_coef']].max(axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine max lasso coefs\n",
    "with open('lasso_results_df.pickle', 'rb') as file:\n",
    "    lasso_results_df = pickle.load(file)\n",
    "\n",
    "# plot distribution of biggest magnitude lasso coefs\n",
    "X = lasso_results_df.copy()\n",
    "zero = 0.0000000001\n",
    "X = X[X['abs_max_coef'] > zero]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(X['abs_max_coef'], bins=100)\n",
    "plt.title('Distribution of biggest magnitude LASSO coefficients')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "lasso_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba03739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare distributions of max and min coefs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(X['abs_max_coef'], bins=100)\n",
    "plt.hist(X['max_coef'], bins=100)\n",
    "plt.hist(X['min_coef'], bins=100)\n",
    "\n",
    "plt.title('Distribution of biggest magnitude LASSO coefficients')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"results_df.pickle\"\n",
    "with open(fp, \"rb\") as files:\n",
    "    results_df = pickle.load(files)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate and compare predictions\n",
    "def evaluate_forecasts(results_df, true_values):\n",
    "    lasso_preds = results_df['lasso']\n",
    "    ar_preds = results_df['ar']\n",
    "    dates = results_df['date']\n",
    "    true_vals = true_values.loc[dates]\n",
    "\n",
    "    # Compute evaluation metrics (e.g., R², MSE)\n",
    "    lasso_r2 = np.corrcoef(lasso_preds, true_vals)[0, 1]**2 if len(lasso_preds) > 1 else np.nan\n",
    "    ar_r2 = np.corrcoef(ar_preds, true_vals)[0, 1]**2 if len(ar_preds) > 1 else np.nan\n",
    "\n",
    "    evaluation = {'lasso_r2': lasso_r2, 'ar_r2': ar_r2}\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "true_values = return_features_df[f'{focal_ticker}_return']\n",
    "evaluation_results = evaluate_forecasts(results_df, true_values)\n",
    "\n",
    "print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8908e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
